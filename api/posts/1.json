{"total":15,"pageSize":10,"pageCount":2,"data":[{"title":"如何更好利用Google进行检索","slug":"如何更好利用google进行检索","date":"2021-04-04T01:29:15.832Z","updated":"2021-04-04T01:57:03.527Z","comments":true,"path":"api/articles/如何更好利用google进行检索.json","excerpt":"","keywords":null,"cover":null,"content":"<p>我们在生活中经常使用各种搜索引擎，但实际上我们对于搜索引擎的了解却少之又少。搜索引擎不仅仅是键入关键词就万事大吉的，这样的搜索引擎没有被充分利用。在这篇文章中，我会对于搜索引擎的使用做一个实用向的介绍，介绍一些实用的命令，让搜索变得更加sharp。</p>\n<p>善用搜索功能，可以一定程度上增强自己的自主性，避免被辣鸡推荐算法驯化。</p>\n<p>【比较好用的功能加了粗。】</p>\n<p>“我竟然可以用google主站实现这些事情！”</p>\n<ol>\n<li>搜索社交媒介：在社交媒介之前加上@站点名，可以在搜索引擎站内实现内容搜索。例如：“@twitter say hello！”（**<em>注：出于对用户隐私的考量，很多社交网站已经拒绝了搜索引擎对于站点的爬虫，所以通过这种方法搜索能得到的结果少之又少。建议直接去社交网站站内进行搜索。**</em>）</li>\n<li><strong>搜索某一价位的商品</strong>：在价位前面加上货币符号。例如“相机 ￥400”，或者“camera $400”.<br><strong>搜索某一价格区间的商品</strong>：在上面的基础上，把价格改成￥400..￥1000即可。</li>\n<li>搜索标签： #throwbackthursday</li>\n<li><strong>排除某个关键词</strong>：在“-”后面加上你不想出现在结果中的词汇，如：jaguar speed -car</li>\n<li><strong>需要某个关键词</strong>：把必须要出现在结果中的词用双引号（英文）括起来，如”社会科学”，搜索出来的结果中都有社会科学这四个字。</li>\n<li>使用“或”逻辑搜索，在结果中做选择：马拉松OR比赛</li>\n<li>站内搜索：在前面加上“site:”，冒号后面不要有空格！（**<em>同样因为一些网站会有反爬限制，这一条未必十分奏效**</em>）</li>\n<li>搜索与某网站相关的其他站点：在站名前面加上“related:”（**<em>我还没搞明白这一条是什么意思，比如我搜“related:zhihu.com”,出来的结果没有知乎，出来的是豆瓣、36氪、bilibili。**</em>）</li>\n<li>搜索谷歌缓存的站点：在站点名前面加上“cache:”，注意不要让搜索返回一些有害的结果。（**<em>同样没懂这是什么意思**</em>）</li>\n<li><strong>搜索特定大小的图片</strong>：例如想搜索500*400的图片，在搜索的时候加上“imagesize:500x400”。500和400中间的乘号是小写字母x。</li>\n<li>对于对算法无意义的标点，谷歌采取忽略处理。</li>\n</ol>\n<p>参考资料：</p>\n<ol>\n<li>本文基于<a href=\"https://support.google.com/websearch/answer/2466433?hl=en&rd=2&visit_id=637530964642003360-2919006400\">special commands in Google</a>进行写作</li>\n<li>如果对搜索引擎有更多的兴趣，dive into<a href=\"https://searchengineland.com/\">search engine land</a></li>\n</ol>\n","text":"我们在生活中经常使用各种搜索引擎，但实际上我们对于搜索引擎的了解却少之又少。搜索引擎不仅仅是键入关键词就万事大吉的，这样的搜索引擎没有被充分利用。在这篇文章中，我会对于搜索引擎的使用做一个实用向的介绍，介绍一些实用的命令，让搜索变得更加sharp。善用搜索功能，可以一定程度上增强","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"生活技巧","slug":"生活技巧","count":1,"path":"api/tags/生活技巧.json"}]},{"title":"自然语言处理技术带来的算法偏见：表现、成因、影响及对策","slug":"算法偏见","date":"2021-04-03T03:22:01.575Z","updated":"2021-04-03T15:07:35.622Z","comments":true,"path":"api/articles/算法偏见.json","excerpt":"","keywords":null,"cover":null,"content":"<h1 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h1><h1 id=\"自然语言处理技术：流程及应用场景\"><a href=\"#自然语言处理技术：流程及应用场景\" class=\"headerlink\" title=\"自然语言处理技术：流程及应用场景\"></a>自然语言处理技术：流程及应用场景</h1><h1 id=\"算法偏见的产生\"><a href=\"#算法偏见的产生\" class=\"headerlink\" title=\"算法偏见的产生\"></a>算法偏见的产生</h1><h1 id=\"算法偏见带来的潜在影响\"><a href=\"#算法偏见带来的潜在影响\" class=\"headerlink\" title=\"算法偏见带来的潜在影响\"></a>算法偏见带来的潜在影响</h1><h1 id=\"可能应对的策略\"><a href=\"#可能应对的策略\" class=\"headerlink\" title=\"可能应对的策略\"></a>可能应对的策略</h1><h1 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h1><h1 id=\"对应文章\"><a href=\"#对应文章\" class=\"headerlink\" title=\"对应文章\"></a>对应文章</h1><p><a href=\"https://zhuanlan.zhihu.com/p/341837763\">机器学习bias里的一些想法和思考</a></p>\n","text":"引言自然语言处理技术：流程及应用场景算法偏见的产生算法偏见带来的潜在影响可能应对的策略结语对应文章机器学习bias里的一些想法和思考","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"算法偏见","slug":"算法偏见","count":1,"path":"api/tags/算法偏见.json"}]},{"title":"《TensorFlow自然语言处理》读书笔记","slug":"TensorFlow自然语言处理 读书笔记","date":"2021-04-02T06:24:03.098Z","updated":"2021-04-02T14:14:03.398Z","comments":true,"path":"api/articles/TensorFlow自然语言处理 读书笔记.json","excerpt":"","keywords":null,"cover":null,"content":"<h1 id=\"Cha1-自然语言处理简介\"><a href=\"#Cha1-自然语言处理简介\" class=\"headerlink\" title=\"Cha1 自然语言处理简介\"></a>Cha1 自然语言处理简介</h1><ol>\n<li>NLP技术用来处理大量非结构化数据</li>\n<li>深度学习被广泛应用在NLP任务</li>\n<li>TensorFlow是最直观、最有效的深度学习框架之一（PyTorch大概表示不服？）</li>\n<li>本章回答的问题+主要内容分布：什么是自然语言处理、自然语言处理最重要的用途、NLP方法（传统+DL+全连接神经网络FCNN）、本书技术工具</li>\n<li>（<strong>直接跳转到1.4</strong>）自然语言处理的深度学习方法<ol>\n<li>深度学习彻底改变了机器学习<del>深层模型可以从原始数据中学习丰富的特征，无需使用有限的人工设计特征</del>深层模型使得传统方法更有效，因为深层模型可以同时执行特征学习和任务学习&amp;&amp;深层模型中的大量参数，使得人工设计具有更多特征。</li>\n<li>模型可解释性差，如何学习、学习什么，都悬而未决。</li>\n<li>深层模型本质是人工神经网络，输入层-隐藏层-输出层，这构成了原始data-最终预测的端-端模型。隐藏层为深层模型提供动力，负责从原始数据中学习“好”的特征，最终成功解决手头的任务。</li>\n</ol>\n</li>\n<li>本书将会探讨流行且有趣的NLP任务的细节，使用python和TensorFlow工具。<br> （注：加粗部分是自己本次要看的，服务于情感分析。）<ol>\n<li>Cha2：如何编写客户端程序：<strong>了解TensorFlow工作流、术语；了解程序中的各种元素</strong>；实现对手写图像分类的功能。</li>\n<li>Cha3：Word2Vec，学习单词的数值表示，反映单词语义：回顾早期方法，突出向量化的优越性；主要看两种Word2Vec技术，skip-gram和CBOW模型。</li>\n<li>Cha4：比较几种算法，讨论对原始Word2Vec的扩展——GloVe技术</li>\n<li>Cha5：卷积神经网络CNN：卷积和池化操作、利用CNN对手写数字图像进行分类的实例、NLP中的CNN应用</li>\n<li>Cha6：递归神经网络RNN，以及利用RNN进行语言生成：RNN方程式、权重优化过程、不同类型RNN、RNN应用、RNN变体。</li>\n<li>Cha7：<strong>LSTM模型介绍</strong>：优势是记住长期信息、环节记忆长期信息、若干改进</li>\n<li>Cha8：继续讨论带有窥孔连接的LSTM、GRU、LSTM：扩展，讨论TF中的RNN API。</li>\n<li>Cha9：魔性学习如何使用LSTM和CNN生成图像标题（描述）</li>\n<li>Cha10：神经机器翻译</li>\n<li>Cha11：NLP的未来</li>\n<li>附录：各种数学数据结构和操作，概率论、Keras（TF高级库）、seq2seq等。</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"Cha2-理解TensorFlow\"><a href=\"#Cha2-理解TensorFlow\" class=\"headerlink\" title=\"Cha2 理解TensorFlow\"></a>Cha2 理解TensorFlow</h1><ol>\n<li>性质：开源分布式数值计算框架</li>\n<li>这本书必须由<a href=\"https://en.wikipedia.org/wiki/Linear_algebra\">线性代数</a>的基础，以及<a href=\"https://en.wikipedia.org/wiki/Artificial_neural_network\">人工神经网络</a>的基本知识才能够理解。然而我几乎没什么基础……（线性代数已然忘光了）</li>\n<li></li>\n</ol>\n","text":"Cha1 自然语言处理简介NLP技术用来处理大量非结构化数据深度学习被广泛应用在NLP任务TensorFlow是最直观、最有效的深度学习框架之一（PyTorch大概表示不服？）本章回答的问题+主要内容分布：什么是自然语言处理、自然语言处理最重要的用途、NLP方法（传统+DL+全连","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","count":2,"path":"api/tags/读书笔记.json"}]},{"title":"对于“xxxx”事件的情感分析尝试","slug":"tensorflow情感分析","date":"2021-04-01T12:08:10.453Z","updated":"2021-04-04T01:21:28.787Z","comments":true,"path":"api/articles/tensorflow情感分析.json","excerpt":"","keywords":null,"cover":null,"content":"<h1 id=\"基于tensorflow的情感分析学习：\"><a href=\"#基于tensorflow的情感分析学习：\" class=\"headerlink\" title=\"基于tensorflow的情感分析学习：\"></a>基于tensorflow的情感分析学习：</h1><ol>\n<li>混淆矩阵（confusion matrix）：用在ML和统计分类的问题中，是一种可视化工具，特别用于监督学习，在无监督学习中叫做匹配矩阵。<ul>\n<li>监督学习（supervised learning）：机器学习的一种方法，由训练资料中学到或建立一个模型，并以此模型推测新的实例。输入（训练集）通常是输入物件（向量）+预期输出。函数的输出可以是一个连续的值（回归分析），或者是预测一个分类标签。</li>\n<li>无监督学习（unsupervised learning）：实现不给已经标记过的训练示例，自动对于输入的资料进行分类或分群。主要运用：聚类分析（cluster analysis）、关系规则（association rule）、维度缩减（dimensionality reduce）。例如在数据聚类情况下，GAN、SOM和ART是最常用的非监督式学习。<br>混淆矩阵实际上是两个维度的相同的联列表（contingency table）。横坐标是“实际的类别”，纵坐标是“预测的类别”，这样一来所有正确的结果都被放到了对角线上，视觉上可以很轻松地检查预测错误。</li>\n</ul>\n</li>\n<li>导入数据的数据结构：<ol>\n<li>从数据的切分上：分成test:train:validation=1:8:1三个部分。</li>\n<li>从来源上（<strong>太麻烦了，还没看完</strong>）：nlp模块中load_dataset导入的，细节可以参考<a href=\"https://huggingface.co/docs/datasets/v0.3.0/add_dataset.html\">文档</a>。<br> Q:什么时候需要用到load_dataset的包？<br> A:当想用自己的dataset的时候，或者想共享一个自己的新的dataset的时候<br> Q:如果自创dataset，有什么要求？<br> A:这里是<a href=\"https://github.com/huggingface/datasets/blob/master/templates/new_dataset_script.py\">模板</a>，但是我还没读懂。<br> Q:关于生成数据集的时候，类和方法的简单科普(和Q2有关)：<ul>\n<li>首先明白什么是<a href=\"https://docs.python.org/zh-cn/3/tutorial/classes.html\">类</a>，什么是<a href=\"https://docs.python.org/zh-cn/3/tutorial/classes.html#method-objects\">方法</a></li>\n</ul>\n</li>\n</ol>\n</li>\n<li>标注（tokenizer）：<br> 这也是huggingface公司旗下的一个模块下的类（<strong>不知道这样说合不合适</strong>），负责标准化输入内容（？）。keras文档中把tokenizer解释成用于把文本向量化的工具，即可以把文本转化成序列。tokenizer的本质是一个类。token是符号，包括单词和标点，tokenization是分词的意思。<br> <a href=\"https://huggingface.co/transformers/main_classes/tokenizer.html\">官方文档</a><br> (<strong>仍然暂时没看</strong>)</li>\n<li>补充和截断序列：<br> 这一步操作主要是把文本转化成矩阵来处理。但是为什么要补齐成为矩阵呢？大概是需要用到数学的地方了，估计后面的运算需要用到矩阵。补齐之后，数据集的tweet条数是其列数，行数就是50，比50个词短的推，向后补齐，比50个词长的推，从前面截断（？）。</li>\n<li>准备标签：<br> 给分的类打上标签，sadness、joy、anger、surprise、fear、love。这里的逻辑应该是，传上来的数据集已经是打过标签的了，统计出来的是原油的个数。这个直方图是大概加起来是训练集的个数，2000个。</li>\n<li>创建模型：<br> 这个模型是用来干什么的呢？直觉是需要tensorflow框架的知识才能解释。<br> 推荐一本书：《TensorFlow自然语言处理》，阅读笔记参看<a href=\"\">这里</a></li>\n<li>训练模型：</li>\n<li>评估模型：</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","text":"基于tensorflow的情感分析学习：混淆矩阵（confusion matrix）：用在ML和统计分类的问题中，是一种可视化工具，特别用于监督学习，在无监督学习中叫做匹配矩阵。监督学习（supervised learning）：机器学习的一种方法，由训练资料中学到或建立一个模型","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"NLP","slug":"NLP","count":1,"path":"api/tags/NLP.json"}]},{"title":"托福单词记忆","slug":"托福备考日记","date":"2021-04-01T10:20:29.795Z","updated":"2021-04-01T10:51:33.439Z","comments":true,"path":"api/articles/托福备考日记.json","excerpt":"","keywords":null,"cover":null,"content":"<ol>\n<li>suspend 通勤（农村-城市）</li>\n<li>polish 加上一些没什么用的东西</li>\n<li></li>\n</ol>\n","text":"suspend 通勤（农村-城市）polish 加上一些没什么用的东西","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"TOEFL","slug":"TOEFL","count":1,"path":"api/tags/TOEFL.json"}]},{"title":"《社会心理学》读书笔记","slug":"社会心理学-David G Myers","date":"2021-04-01T02:55:41.117Z","updated":"2021-04-01T06:43:31.700Z","comments":true,"path":"api/articles/社会心理学-David G Myers.json","excerpt":"","keywords":null,"cover":null,"content":"<p>author: David G Myers</p>\n<p>Cha 2 社会中的自我</p>\n<ol>\n<li>如果需要了解自我，需要注意“焦点/注意力”和“错觉”两方面</li>\n<li>焦点效应（spotlight effect）：人们会把自己看做一切的中心，并直觉上高估别人对自己的关注程度</li>\n<li>透明度错觉（illusion of transparency）：实际上注意到我们的人比我们认为的要少，我们的表现比我们对自己的觉察要更加模糊不清，我们会高估自己的社交失误和公众心理疏忽（public mental slips）</li>\n<li>社会环境对自我觉知具有影响：所谓自我觉知，就是对自己身份的定位，在自己与别人不同的时候，这种觉知变得敏锐。</li>\n<li>人的社会判断具有自我服务性：把责任更多推导对方身上，把功劳更多揽到自己身上</li>\n<li>自我关注激发的社会行为：留下好印象</li>\n<li>对自我的界定：如何看待自己，与我们在关系中的角色紧密相连</li>\n<li>我们的大多数行为是无意识的、是不受意识控制的；但自我会为了社会表现进行一些管理，这有时候会成为幸福的障碍。</li>\n<li>我是谁——回答自我概念（self-concept)的问题——自我图式</li>\n<li>我们世界的核心——我们的自我感觉</li>\n<li>可能的自我：可能自我，即自己梦想的样子（激励、避免成为害怕的样子）</li>\n<li>社会自我：基因+社会经验的双重影响<ol>\n<li>我们扮演的角色——角色扮演成为一种事实</li>\n<li>社会比较——如学业自我概念。我们的生活大部分是围绕着社会比较而进行的，当我们评价某个人的时候，不可能不把他与自己作比较。</li>\n<li>其他人的评价——容易导致“不认同”——如：women in stem——镜像自我：我们以为别人怎么看自己，高估了别人对自己的评价，膨胀了自我意象</li>\n</ol>\n</li>\n<li>接着12.3可以谈一谈性别偏见的话题：性别刻板印象、性别态度和性别歧视</li>\n<li>自我表露的管理：<ol>\n<li>自我妨碍：设置障碍来阻止自己成功（出于自我保护：“没有这个障碍，一定能做得更好”）<br>由于害怕失败，人们会产生如下行为：减少对重要的个人赛事的准备、给对手提供一些有利条件、在任务刚开始时不好好干，以降低自我期待、在那些关系到自我形象的困难任务中不会尽全力</li>\n<li>印象管理：人作为社会性动物，渴望被社会接纳，而且很强烈。<ol>\n<li>自我表露（self-presentation）：我们想要向外在观众和内在观众展现一种受到赞扬的形象。我们致力于管理自己营造的形象。我们通过推诿、边界和道歉等方式来支撑我们的自尊，并检验我们的自我形象。</li>\n<li>社会交往是一种看上去很好，又不为过的微妙平衡。</li>\n<li>自我监控：不断监控自己的行为，以期得到别人的赞许。高自我监控的人往往更少致力于其人际关系，而且更有可能不满意于自己的婚姻生活。低自我监控的人更能按照自己的感觉和信念来说话做事，毫不顾忌听众的态度。</li>\n<li>营造一个既谦逊又有才华的好印象，确实需要一定的社会技巧。</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>傲慢的危险与积极思维的力量——一对相反的事实：<ol>\n<li>两个事实：自我效能感&amp;自我服务偏差。  <ol>\n<li>自我效能感：对自己能力和效率的乐观信念，可以获得很大的回报。有助于人们变得更有韧性，生活得更健康，取得更大的生活和学业成就。<ol>\n<li>自我效能感高的人，会用更平静的心态去解决问题。</li>\n<li>控制自我效能感：积极词汇有助于提升自我效能感</li>\n<li>区分自尊和自我效能：自尊是喜欢自己，自我效能是相信自己有能力做某件事。鼓励某人要从自我效能入手，而不是自尊。</li>\n</ol>\n</li>\n<li>自我服务偏差：<ol>\n<li>因为自恋而疏远他人、对自己有不合理的要求、盲目乐观等等</li>\n<li>提醒自己，自我效能感无法解决所有问题</li>\n</ol>\n</li>\n<li>生活中最了不起的成就，和最令人沮丧的挫折，都来自对自己高标准的预期。</li>\n<li>任何一个真理都是不充分的，因为世界是很复杂的——帕斯卡尔。</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n","text":"author: David G MyersCha 2 社会中的自我如果需要了解自我，需要注意“焦点/注意力”和“错觉”两方面焦点效应（spotlight effect）：人们会把自己看做一切的中心，并直觉上高估别人对自己的关注程度透明度错觉（illusion of transpa","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"读书笔记","slug":"读书笔记","count":2,"path":"api/tags/读书笔记.json"}]},{"title":"python进行文本处理的几个方法总结","slug":"python进行文本处理的几个方法总结","date":"2021-01-29T02:14:40.914Z","updated":"2021-01-30T12:19:00.649Z","comments":true,"path":"api/articles/python进行文本处理的几个方法总结.json","excerpt":"","keywords":null,"cover":null,"content":"<ol>\n<li>关于jupyter notebook的打开：在需要写python脚本的文件夹里面打开的方式是，shift+右键，选择“在此处打开PowerShell窗口”</li>\n<li>文件结构:路径中不用中文，文件结构是：name_code/notebook；数据</li>\n<li>如何用python读写文件：<br> 看类型：<ol>\n<li>读json文件<ol>\n<li>with open语句可以用于打开某语句，格式：<br> with open(‘file_path’,r) as file:<pre><code> report = json.load(file)</code></pre>\n 其中，file_path是传入的文件路径，这个路径是目录+文件名的叠加。<br> 用到了json库。<br> 当需要读到一个文件夹中的所有json文件时，需要导入os库，操作如下：</li>\n<li>json转换为dic：<br> json.load和json.loads的区别？</li>\n</ol>\n</li>\n<li>读xlsx文件</li>\n</ol>\n</li>\n<li>字典中不能出现重复的key，若出现，保留后面的</li>\n</ol>\n","text":"关于jupyter notebook的打开：在需要写python脚本的文件夹里面打开的方式是，shift+右键，选择“在此处打开PowerShell窗口”文件结构:路径中不用中文，文件结构是：name_code/notebook；数据如何用python读写文件：<br> 看类型：","link":"","raw":null,"photos":[],"categories":[],"tags":[]},{"title":"语境学习法","slug":"语境学习法","date":"2021-01-24T02:03:44.013Z","updated":"2021-01-24T02:04:38.329Z","comments":true,"path":"api/articles/语境学习法.json","excerpt":"","keywords":null,"cover":null,"content":"<pre><code>语境学习法是给自己一个</code></pre>\n","text":"语境学习法是给自己一个","link":"","raw":null,"photos":[],"categories":[],"tags":[]},{"title":"李宏毅ML-1-regression","slug":"李宏毅ML-1-regression","date":"2021-01-21T06:24:18.922Z","updated":"2021-01-22T06:59:05.982Z","comments":true,"path":"api/articles/李宏毅ML-1-regression.json","excerpt":"","keywords":null,"cover":null,"content":"<blockquote>\n<p>为了更好的调动听课的思路，化被动吸收为主动思考，笔者采用Q&amp;A的形式来展示课程笔记。与此同时，为了锻炼笔者的英语书写能力，会尽可能采用英文进行书写。</p>\n</blockquote>\n<hr>\n<ol>\n<li>Q：What is regression？<br>A：<blockquote>\n<p>Regression is a statistical method used in finance, investing, and other disciplines that attempts to determine the strength and character of the relationship between one dependent variable (usually denoted by Y) and a series of other variables (known as independent variables).<br>关键词：统计模型 变量拟合 独立变量 非独立变量<br>In machine learning, regression is a method by which we can use some data to find out a predictive function. Then we use some new data as input, we can get unknown output that the known data can predict.</p>\n</blockquote>\n</li>\n<li>Q：What is a model? Why do we need a model? How do we find a model?<br>In this context, model is the best function of the original set of functions.</li>\n<li>Q：What is Gradient Descend？（☆）<br>We use this method to find an optimal answer. When gradient goes to zero, the value of the function goes to minimal. In our context, we use the loss function to evalueate how effective our model function(or regression function) is. We need to find the minimal of the loss function, as well as the pixel of the minimal point, for the number of pixel shows the best model function.</li>\n<li></li>\n</ol>\n","text":"为了更好的调动听课的思路，化被动吸收为主动思考，笔者采用Q&amp;A的形式来展示课程笔记。与此同时，为了锻炼笔者的英语书写能力，会尽可能采用英文进行书写。Q：What is regression？<br>A：Regression is a statistical method ","link":"","raw":null,"photos":[],"categories":[],"tags":[]},{"title":"Learning|","slug":"医疗健康产品调研","date":"2021-01-18T03:13:33.145Z","updated":"2021-01-21T03:04:22.439Z","comments":true,"path":"api/articles/医疗健康产品调研.json","excerpt":"","keywords":null,"cover":null,"content":"<pre><code>根据waston health官网阐述的资料，</code></pre>\n","text":"根据waston health官网阐述的资料，","link":"","raw":null,"photos":[],"categories":[],"tags":[]}]}