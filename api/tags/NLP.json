{"name":"NLP","slug":"NLP","count":1,"postlist":[{"title":"对于“xxxx”事件的情感分析尝试","slug":"tensorflow情感分析","date":"2021-04-01T12:08:10.453Z","updated":"2021-04-07T02:35:47.310Z","comments":true,"path":"api/articles/tensorflow情感分析.json","excerpt":"","keywords":null,"cover":null,"content":"<h1 id=\"基于tensorflow的情感分析学习：\"><a href=\"#基于tensorflow的情感分析学习：\" class=\"headerlink\" title=\"基于tensorflow的情感分析学习：\"></a>基于tensorflow的情感分析学习：</h1><ol>\n<li>混淆矩阵（confusion matrix）：用在ML和统计分类的问题中，是一种可视化工具，特别用于监督学习，在无监督学习中叫做匹配矩阵。<ul>\n<li>监督学习（supervised learning）：机器学习的一种方法，由训练资料中学到或建立一个模型，并以此模型推测新的实例。输入（训练集）通常是输入物件（向量）+预期输出。函数的输出可以是一个连续的值（回归分析），或者是预测一个分类标签。</li>\n<li>无监督学习（unsupervised learning）：实现不给已经标记过的训练示例，自动对于输入的资料进行分类或分群。主要运用：聚类分析（cluster analysis）、关系规则（association rule）、维度缩减（dimensionality reduce）。例如在数据聚类情况下，GAN、SOM和ART是最常用的非监督式学习。<br>混淆矩阵实际上是两个维度的相同的联列表（contingency table）。横坐标是“实际的类别”，纵坐标是“预测的类别”，这样一来所有正确的结果都被放到了对角线上，视觉上可以很轻松地检查预测错误。</li>\n</ul>\n</li>\n<li>导入数据的数据结构：<ol>\n<li>从数据的切分上：分成test:train:validation=1:8:1三个部分。</li>\n<li>从来源上：nlp模块中load_dataset导入的，细节可以参考<a href=\"https://huggingface.co/docs/datasets/v0.3.0/add_dataset.html\">文档</a>。<br> Q:什么时候需要用到load_dataset的包？<br> A:当想用自己的dataset的时候，或者想共享一个自己的新的dataset的时候<br> Q:如果自创dataset，有什么要求？<br> A:这里是<a href=\"https://github.com/huggingface/datasets/blob/master/templates/new_dataset_script.py\">模板</a>，但是我还没读懂。<br> Q:关于生成数据集的时候，类和方法的简单科普(和Q2有关)：<ul>\n<li>首先明白什么是<a href=\"https://docs.python.org/zh-cn/3/tutorial/classes.html\">类</a>，什么是<a href=\"https://docs.python.org/zh-cn/3/tutorial/classes.html#method-objects\">方法</a></li>\n<li>整体的大思路是从General到Specific，所谓Genercal就是普遍的数据组织方法和类，Specific是值得每一个数据集加载的脚本。</li>\n<li>DatasetBuilder是中心环节，其参考BuilderConfig，生成DatasetInfo和和Dataset，而BuiderConfig则是最基础的，生成DatasetBuilder的模块。所以说数据集并不是只是一个dataset这么简单，自动化的数据集的话需要的是一套完整的流程。【我想，自己做一个csv也是可以的，但是不太清楚格式。】general的部分结束了之后，来到specific的部分，由MyBuilderConfig和MyDatasetBuilder确定。</li>\n<li>创建一个新的数据集载入脚本（dataset loading script），必须要将nlp.DatasetBuilder类中三个方法特别化，即._info(),._split_generator(),._generate_examples()</li>\n<li>写一个新的数据集的流程：加入数据集的metadata-下载数据文件并组织切分-生成每一个切分的样本-特殊化少部分的数据集配置-监测数据集加载样本</li>\n</ul>\n</li>\n</ol>\n</li>\n<li>标注（tokenizer）：<br> 这也是huggingface公司旗下的一个模块下的类（<strong>不知道这样说合不合适</strong>），负责标准化输入内容（？）。keras文档中把tokenizer解释成用于把文本向量化的工具，即可以把文本转化成序列。tokenizer的本质是一个类。token是符号，包括单词和标点，tokenization是分词的意思。<br> <a href=\"https://huggingface.co/transformers/main_classes/tokenizer.html\">官方文档</a><br> (<strong>仍然暂时没看</strong>)</li>\n<li>补充和截断序列：<br> 这一步操作主要是把文本转化成矩阵来处理。但是为什么要补齐成为矩阵呢？大概是需要用到数学的地方了，估计后面的运算需要用到矩阵。补齐之后，数据集的tweet条数是其列数，行数就是50，比50个词短的推，向后补齐，比50个词长的推，从前面截断（？）。</li>\n<li>准备标签：<br> 给分的类打上标签，sadness、joy、anger、surprise、fear、love。这里的逻辑应该是，传上来的数据集已经是打过标签的了，统计出来的是原油的个数。这个直方图是大概加起来是训练集的个数，2000个。</li>\n<li>创建模型：<br> 这个模型是用来干什么的呢？直觉是需要tensorflow框架的知识才能解释。<br> 推荐一本书：《TensorFlow自然语言处理》，阅读笔记参看<a href=\"\">这里</a>。<br> 这个调用的是Keras中sequential模型的的API，所以我们着重讲keras中的sequential API。</li>\n</ol>\n<ol start=\"7\">\n<li>训练模型：</li>\n<li>评估模型：</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1>","text":"基于tensorflow的情感分析学习：混淆矩阵（confusion matrix）：用在ML和统计分类的问题中，是一种可视化工具，特别用于监督学习，在无监督学习中叫做匹配矩阵。监督学习（supervised learning）：机器学习的一种方法，由训练资料中学到或建立一个模型","link":"","raw":null,"photos":[],"categories":[],"tags":[{"name":"NLP","slug":"NLP","count":1,"path":"api/tags/NLP.json"}]}]}